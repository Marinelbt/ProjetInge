---
title: "Machine learning"
author: "Amélie Brejot"
date: "2024-12-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.show = "hide")

library(rsample)
library(rpart)
library(rpart.plot)
library(caret)
```


# Arbres

```{r}
set.seed(123)
#data <- read.csv("../Data/data_59_min.csv")
data <- data_mod1

data$effet_positif <- as.factor(data$effet_positif)
data$TM_derniere_min <- as.factor(data$TM_derniere_min)
data$TM_derniere_min_adverse <- as.factor(data$TM_derniere_min_adverse)
data$HF <- as.factor(data$HF)
data$equipe <- as.factor(data$equipe)
data$DM_adverse <- as.factor(data$DM_adverse)
data$DM <- as.factor(data$DM)
data$statut_59_min <- as.factor(data$statut_59_min)
data$saison <- as.factor(data$saison)
data$division <- as.factor(data$division)
data$journee <- as.factor(data$journee)

data.split <- initial_split(data_mod1, prop = 0.80)
data.train <- training(data.split)
data.test <- testing(data.split)
```



```{r}
set.seed(123)
ctrl <- trainControl(method = "cv", number = 10)

# Entraîner l'arbre avec validation croisée
cv_tree <- train(
  effet_positif ~ TM_derniere_min + TM_derniere_min_adverse + DM_adverse + DM + ecart_classement + statut_59_min, 
  data = data.train, 
  method = "rpart",
  trControl = ctrl
)

print(cv_tree)

tree <- rpart(effet_positif ~ TM_derniere_min + TM_derniere_min_adverse + DM_adverse + DM + ecart_classement + statut_59_min,
              data = data.train,
              method = "class",
              control = rpart.control(maxdepth = 30, minsplit = 1, cp =  cv_tree$bestTune))


plotcp(tree)
printcp(tree)

rpart.plot(tree)

pdf("arbre_1.pdf", width = 10, height = 7)
rpart.plot(tree)
dev.off()

# Prédictions sur les données d'entraînement
pred_train <- predict(tree, newdata = data.test, type = "class")

# Calcul du taux de précision
mean(pred_train == data.test$effet_positif)

confusionMatrix(pred_train, data.test$effet_positif)
```

Analyse d'une feuille (0, 0.15, 43%) :
La classe majoritaire choisie est pas d'effet positif pour le recevant (0)
Cette classe représente 15% de la feuille.
Cette feuille contient 43% du jeu de données.

# Arbre gagnant

```{r}
set.seed(123)
data_g <- data_mod1 %>% filter(statut_59_min == -1)

data.split.g <- initial_split(data_mod1, prop = 0.80)
data.train.g <- training(data.split.g)
data.test.g <- testing(data.split.g)

ctrl <- trainControl(method = "cv", number = 10)

# Entraîner l'arbre avec validation croisée
cv_tree <- train(
  effet_positif ~ TM_derniere_min + TM_derniere_min_adverse + DM_adverse + DM + ecart_classement, 
  data = data.train.g, 
  method = "rpart",
  trControl = ctrl
)

# Résultats de la validation croisée
print(cv_tree)

tree <- rpart(effet_positif ~ TM_derniere_min + TM_derniere_min_adverse + DM_adverse + DM + ecart_classement,
              data = data.train.g,
              method = "class",
              control = rpart.control(maxdepth = 30, minsplit = 1, cp =  cv_tree$bestTune))

rpart.plot(tree)

# Prédictions sur les données d'entraînement
pred_train <- predict(tree, newdata = data.test.g, type = "class")

# Calcul du taux de précision
mean(pred_train == data.test.g$effet_positif)

confusionMatrix(pred_train, data.test.g$effet_positif)
```


```{r}
prediction <- predict(tree, data.test, type = "class")

data.test$effet_positif <- factor(data.test$effet_positif, levels = levels(prediction))

confusionMatrix(prediction, data.test$effet_positif)
```


