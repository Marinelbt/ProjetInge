---
title: "Machine learning"
author: "Amélie Brejot"
date: "2024-12-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.show = "hide")

library(rsample)
library(rpart)
library(rpart.plot)
library(caret)
```


# Arbres

```{r}
set.seed(123)
#data <- read.csv("../Data/data_59_min.csv")
data <- data_mod1

data$effet_positif <- as.factor(data$effet_positif)
data$TM_derniere_min <- as.factor(data$TM_derniere_min)
data$TM_derniere_min_adverse <- as.factor(data$TM_derniere_min_adverse)
data$HF <- as.factor(data$HF)
data$equipe <- as.factor(data$equipe)
data$DM_adverse <- as.factor(data$DM_adverse)
data$DM <- as.factor(data$DM)
data$statut_59_min <- as.factor(data$statut_59_min)
data$saison <- as.factor(data$saison)
data$division <- as.factor(data$division)
data$journee <- as.factor(data$journee)

data.split <- initial_split(data_mod1, prop = 0.80)
data.train <- training(data.split)
data.test <- testing(data.split)
```



```{r}
control_params <- rpart.control(maxdepth = 30, minsplit = 1, cp = 0.002)
# grid <- expand.grid(
#   cp = c(0.001, 0.0015, 0.0023, 0.0037, 0.002)
# )
# control <- trainControl(method = "cv", number = 5)
# 
# model <- train(
#   effet_positif ~ TM_derniere_min + TM_derniere_min_adverse + DM_adverse + DM + ecart_classement,
#   data = data.train,
#   method = "rpart",
#   trControl = control,
#   tuneGrid = grid,
# )
# 
# print(model)
# print(model$bestTune)
# 
# rpart.plot(model$finalModel)

tree <- rpart(effet_positif ~ TM_derniere_min + TM_derniere_min_adverse + DM_adverse + DM + ecart_classement,
              data = data.train,
              method = "class",
              control = control_params)


plotcp(tree)
printcp(tree)

rpart.plot(tree)

# pdf("arbre.pdf", width = 10, height = 7)
# rpart.plot(tree)
# dev.off()
```

Analyse d'une feuille (0, 0.15, 43%) :
La classe majoritaire choisie est pas d'effet positif pour le recevant (0)
Cette classe représente 15% de la feuille.
Cette feuille contient 43% du jeu de données.

# Arbre gagnant

```{r}

data.split.g <- data_mod1 %>% 
  filter(statut_59_min == 1) %>% 
  initial_split(prop = 0.80)
data.train.g <- training(data.split.g)
data.test.g <- testing(data.split.g)

tree <- rpart(effet_positif ~ TM_derniere_min + TM_derniere_min_adverse + DM_adverse + DM + ecart_classement,
              data = data.train.g,
              method = "class",
              control = rpart.control(maxdepth = 30, minsplit = 1, cp = 0.0000000000000000000000000000001))

printcp(tree)
```


```{r}
prediction <- predict(tree, data.test, type = "class")

data.test$effet_positif <- factor(data.test$effet_positif, levels = levels(prediction))

confusionMatrix(prediction, data.test$effet_positif)
```


